#!/usr/bin/env python3
"""
ä»_bookç›®å½•ä¸­é€’å½’æå–æ‰€æœ‰HTMLæ–‡ä»¶çš„1ã€2ã€3çº§æ ‡é¢˜ï¼Œå¹¶ä»¥Markdownæ ¼å¼ä¿å­˜ã€‚

è¯¥è„šæœ¬ä¼šï¼š
1. é€’å½’éå†_bookç›®å½•ä¸‹çš„æ‰€æœ‰HTMLæ–‡ä»¶
2. æå–æ¯ä¸ªæ–‡ä»¶ä¸­æœ‰ç« èŠ‚ç¼–å·çš„h1ã€h2å’Œh3æ ‡é¢˜
3. æŒ‰ç« èŠ‚ç¼–å·æ’åºåï¼Œå°†æå–çš„æ ‡é¢˜æŒ‰Markdownæ ¼å¼ä¿å­˜åˆ°æ–‡ä»¶ä¸­
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Optional
from bs4 import BeautifulSoup


class Heading:
    """è¡¨ç¤ºä¸€ä¸ªæ ‡é¢˜çš„ç±»"""
    
    def __init__(self, level: int, text: str, chapter_number: str, file_path: str):
        self.level = level
        self.text = text
        self.chapter_number = chapter_number
        self.file_path = file_path
    
    def __repr__(self):
        return f"Heading(level={self.level}, chapter_number='{self.chapter_number}', text='{self.text}')"


def parse_chapter_number(chapter_number: str) -> Tuple[List[int], str]:
    """
    è§£æç« èŠ‚ç¼–å·ï¼Œè¿”å›ç”¨äºæ’åºçš„æ•°å­—åˆ—è¡¨å’ŒåŸå§‹å­—ç¬¦ä¸²ã€‚
    
    Args:
        chapter_number: ç« èŠ‚ç¼–å·å­—ç¬¦ä¸²ï¼Œå¦‚ "1.2.3" æˆ– "12"
        
    Returns:
        (æ•°å­—åˆ—è¡¨, åŸå§‹å­—ç¬¦ä¸²) ä¾‹å¦‚: ([1, 2, 3], "1.2.3")
    """
    # æå–æ‰€æœ‰æ•°å­—
    numbers = re.findall(r'\d+', chapter_number)
    try:
        return [int(n) for n in numbers], chapter_number
    except ValueError:
        return [999999], chapter_number  # æ— æ³•è§£æçš„æ”¾åˆ°æœ€å


def extract_headings_from_html(file_path: str) -> List[Heading]:
    """
    ä»HTMLæ–‡ä»¶ä¸­æå–æœ‰ç« èŠ‚ç¼–å·çš„h1ã€h2å’Œh3æ ‡é¢˜ã€‚
    
    Args:
        file_path: HTMLæ–‡ä»¶çš„è·¯å¾„
        
    Returns:
        åŒ…å«Headingå¯¹è±¡çš„åˆ—è¡¨
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        soup = BeautifulSoup(content, 'html.parser')
        headings = []
        
        # æå–h1, h2, h3æ ‡é¢˜
        for level in [1, 2, 3]:
            tag_name = f'h{level}'
            for heading_tag in soup.find_all(tag_name):
                # æŸ¥æ‰¾ç« èŠ‚ç¼–å·
                chapter_number = extract_chapter_number(heading_tag)
                
                if chapter_number:  # åªä¿ç•™æœ‰ç« èŠ‚ç¼–å·çš„æ ‡é¢˜
                    # æå–çº¯æ–‡æœ¬ï¼Œå»é™¤HTMLæ ‡ç­¾å’Œå¤šä½™ç©ºç™½
                    text = heading_tag.get_text(strip=True)
                    if text:
                        headings.append(Heading(level, text, chapter_number, file_path))
                
        return headings
        
    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return []


def extract_chapter_number(heading_tag) -> Optional[str]:
    """
    ä»æ ‡é¢˜æ ‡ç­¾ä¸­æå–ç« èŠ‚ç¼–å·ã€‚
    
    Args:
        heading_tag: BeautifulSoupæ ‡ç­¾å¯¹è±¡
        
    Returns:
        ç« èŠ‚ç¼–å·å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    """
    # æ–¹æ³•1ï¼šæŸ¥æ‰¾ data-number å±æ€§
    chapter_number = heading_tag.get('data-number')
    if chapter_number:
        return chapter_number
    
    # æ–¹æ³•2ï¼šæŸ¥æ‰¾åŒ…å« chapter-number ç±»çš„ span
    chapter_span = heading_tag.find('span', class_='chapter-number')
    if chapter_span:
        return chapter_span.get_text(strip=True)
    
    # æ–¹æ³•3ï¼šæŸ¥æ‰¾åŒ…å« header-section-number ç±»çš„ span
    section_span = heading_tag.find('span', class_='header-section-number')
    if section_span:
        return section_span.get_text(strip=True)
    
    # æ–¹æ³•4ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾ç« èŠ‚ç¼–å·æ¨¡å¼
    text = heading_tag.get_text()
    # åŒ¹é…å¼€å¤´çš„æ•°å­—æ¨¡å¼ï¼Œå¦‚ "1 ", "1.2 ", "1.2.3 "
    match = re.match(r'^(\d+(?:\.\d+)*)\s+', text)
    if match:
        return match.group(1)
    
    return None


def find_html_files(directory: str) -> List[str]:
    """
    é€’å½’æŸ¥æ‰¾ç›®å½•ä¸‹æ‰€æœ‰çš„HTMLæ–‡ä»¶ã€‚
    
    Args:
        directory: è¦æœç´¢çš„ç›®å½•è·¯å¾„
        
    Returns:
        HTMLæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    html_files = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.html'):
                html_files.append(os.path.join(root, file))
    return sorted(html_files)


def sort_headings(headings: List[Heading]) -> List[Heading]:
    """
    æŒ‰ç« èŠ‚ç¼–å·å¯¹æ ‡é¢˜è¿›è¡Œæ’åºã€‚
    
    Args:
        headings: æ ‡é¢˜åˆ—è¡¨
        
    Returns:
        æ’åºåçš„æ ‡é¢˜åˆ—è¡¨
    """
    def sort_key(heading: Heading):
        numbers, _ = parse_chapter_number(heading.chapter_number)
        return numbers
    
    return sorted(headings, key=sort_key)


def generate_markdown_content(headings: List[Heading], base_dir: str) -> str:
    """
    ç”ŸæˆMarkdownæ ¼å¼çš„å†…å®¹ã€‚
    
    Args:
        headings: æ’åºåçš„æ ‡é¢˜åˆ—è¡¨
        base_dir: åŸºç¡€ç›®å½•è·¯å¾„ï¼Œç”¨äºç”Ÿæˆç›¸å¯¹è·¯å¾„
        
    Returns:
        Markdownæ ¼å¼çš„å­—ç¬¦ä¸²
    """
    markdown_lines = []
    markdown_lines.append("# ç”µå­è®²ä¹‰æ ‡é¢˜ç›®å½•\n")
    markdown_lines.append(f"æœ¬æ–‡æ¡£åŒ…å«ä» `{base_dir}` ç›®å½•æå–çš„æ‰€æœ‰HTMLæ–‡ä»¶çš„æœ‰ç« èŠ‚ç¼–å·çš„1ã€2ã€3çº§æ ‡é¢˜ã€‚")
    markdown_lines.append("æ ‡é¢˜æŒ‰ç« èŠ‚ç¼–å·æ’åºã€‚\n")
    markdown_lines.append("---\n")
    
    current_file = None
    
    for heading in headings:
        # è·å–ç›¸å¯¹äºåŸºç¡€ç›®å½•çš„è·¯å¾„
        relative_path = os.path.relpath(heading.file_path, base_dir)
        
        # å¦‚æœæ˜¯æ–°æ–‡ä»¶ï¼Œæ·»åŠ æ–‡ä»¶æ ‡é¢˜
        if relative_path != current_file:
            current_file = relative_path
            markdown_lines.append(f"\n## ğŸ“ æ–‡ä»¶: {relative_path}\n")
        
        # æ·»åŠ æ ‡é¢˜ï¼Œæ ¹æ®çº§åˆ«ä½¿ç”¨ä¸åŒçš„Markdownæ ¼å¼
        if heading.level == 1:
            markdown_lines.append(f"# {heading.text}")
        elif heading.level == 2:
            markdown_lines.append(f"## {heading.text}")
        elif heading.level == 3:
            markdown_lines.append(f"### {heading.text}")
        
        markdown_lines.append("")  # æ·»åŠ ç©ºè¡Œ
    
    return "\n".join(markdown_lines)


def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ ‡é¢˜æå–å’ŒMarkdownæ–‡ä»¶ç”Ÿæˆã€‚
    """
    # è®¾ç½®ç›®å½•è·¯å¾„
    book_dir = "_book"
    output_file = "headings_extracted.md"
    
    # æ£€æŸ¥_bookç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(book_dir):
        print(f"é”™è¯¯ï¼šç›®å½• '{book_dir}' ä¸å­˜åœ¨ï¼")
        return
    
    print(f"å¼€å§‹æ‰«æ '{book_dir}' ç›®å½•...")
    
    # æŸ¥æ‰¾æ‰€æœ‰HTMLæ–‡ä»¶
    html_files = find_html_files(book_dir)
    
    if not html_files:
        print(f"åœ¨ '{book_dir}' ç›®å½•ä¸­æœªæ‰¾åˆ°HTMLæ–‡ä»¶ï¼")
        return
    
    print(f"æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
    
    # æå–æ‰€æœ‰æ ‡é¢˜
    print("æ­£åœ¨æå–æœ‰ç« èŠ‚ç¼–å·çš„æ ‡é¢˜...")
    all_headings = []
    
    for html_file in html_files:
        headings = extract_headings_from_html(html_file)
        all_headings.extend(headings)
    
    print(f"æå–åˆ° {len(all_headings)} ä¸ªæœ‰ç« èŠ‚ç¼–å·çš„æ ‡é¢˜")
    
    # æŒ‰ç« èŠ‚ç¼–å·æ’åº
    print("æ­£åœ¨æŒ‰ç« èŠ‚ç¼–å·æ’åº...")
    sorted_headings = sort_headings(all_headings)
    
    # ç”ŸæˆMarkdownå†…å®¹
    print("æ­£åœ¨ç”ŸæˆMarkdownå†…å®¹...")
    markdown_content = generate_markdown_content(sorted_headings, book_dir)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"âœ… æ ‡é¢˜æå–å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° '{output_file}'")
        print(f"ğŸ“ å¤„ç†äº† {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
        print(f"ğŸ“‘ æå–äº† {len(sorted_headings)} ä¸ªæœ‰ç« èŠ‚ç¼–å·çš„æ ‡é¢˜")
        
        # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
        level_counts = {1: 0, 2: 0, 3: 0}
        for heading in sorted_headings:
            level_counts[heading.level] += 1
        
        print(f"ğŸ“Š æ ‡é¢˜ç»Ÿè®¡: H1={level_counts[1]}, H2={level_counts[2]}, H3={level_counts[3]}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")


if __name__ == "__main__":
    main()